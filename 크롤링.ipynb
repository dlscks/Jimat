{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJW/OgM66cdxKQZn+xD4s5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dlscks/Jimat/blob/master/%ED%81%AC%EB%A1%A4%EB%A7%81.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7k05N1MznvWt"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/MyDrive/seoulfood"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install selenium\n",
        "!pip install -U  urllib3 requests"
      ],
      "metadata": {
        "id": "K1ZApqStn1St"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ],
      "metadata": {
        "id": "NblmX47pt8DM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gu_list = ['마포구','서대문구','은평구','종로구','중구','용산구','성동구','광진구',\n",
        "           '동대문구','성북구','강북구','도봉구','노원구','중랑구','강동구','송파구',\n",
        "           '강남구','서초구','관악구','동작구','영등포구','금천구','구로구','양천구','강서구']"
      ],
      "metadata": {
        "id": "XzfG718FrTD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 25개구 for문으로 돌려서 음식점 정보 크롤링하기\n",
        "\n",
        "import os\n",
        "from time import sleep\n",
        "import time\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.common.exceptions import ElementNotInteractableException\n",
        "from selenium.common.exceptions import NoSuchElementException\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.webdriver.common.by import By\n",
        "\n",
        "##########################################################################\n",
        "##################### variable related selenium ##########################\n",
        "##########################################################################\n",
        "# 서울 특별시 구 리스트\n",
        "gu_list = ['강남구']\n",
        "\n",
        "\n",
        "# csv 파일에 헤더 만들어 주기\n",
        "\n",
        "for index, gu_name in enumerate(gu_list):\n",
        "    k=0\n",
        "    fileName = '강남구url.csv' # index.__str__() + '_' + gu_name + '.'+'csv'\n",
        "    file = open(fileName, 'w', encoding='utf-8-sig')\n",
        "    file.write(\"url\" + \"|\" +\"구\" + \"|\" + \"ID\" + \"|\" +\"맛집명\" + \"|\" + \"타입\" +\"|\" + \"주소\" + \"|\" + \"영업시간\" + \"|\" + \"전화번호\" + \"|\" + \"대표사진주소\" + \"|\" + \"평점\" +\"\\n\")\n",
        "    file.close()                                    # 처음에 csv파일에 칼럼명 만들어주기\n",
        "    \n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument('--headless')        # Head-less 설정\n",
        "    options.add_argument('--no-sandbox')\n",
        "    options.add_argument('--disable-dev-shm-usage')\n",
        "    driver = webdriver.Chrome('chromedriver', options=options)\n",
        "    # options.add_argument('headless')\n",
        "    options.add_argument(\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.198 Safari/537.36   \")\n",
        "    options.add_argument('lang=ko_KR')\n",
        "    chromedriver_path = \"D:/lsy/chromedriver.exe\"\n",
        "    #driver = webdriver.Chrome(os.path.join(os.getcwd(), chromedriver_path), options=options)  # chromedriver 열기\n",
        "    driver.get('https://map.kakao.com/')  # 주소 가져오기\n",
        "     #1.search텍스트창 가져오기\n",
        "    search_area = driver.find_element(By.XPATH,'//*[@id=\"search.keyword.query\"]') # 검색 창\n",
        "    search_area.send_keys(gu_name + ' 맛집')  # 검색어 입력\n",
        "    #2.검색누르기\n",
        "    driver.find_element(By.XPATH,'//*[@id=\"search.keyword.submit\"]').send_keys(Keys.ENTER)  # Enter로 검색\n",
        "    driver.implicitly_wait(3) # 기다려 주자\n",
        "    #3.더보기란 클릭하기\n",
        "    more_page = driver.find_element(By.ID,\"info.search.place.more\")\n",
        "    # more_page.click()\n",
        "    #more_page.send_keys(Keys.ENTER) # 더보기 누르고\n",
        "    driver.execute_script(\"arguments[0].click();\",more_page)\n",
        "    # print(more_page)\n",
        "    # 첫 번째 검색 페이지 끝\n",
        "    # driver.implicitly_wait(5) # 기다려 주자\n",
        "    time.sleep(1)\n",
        "\n",
        "    next_btn = driver.find_element(By.ID,\"info.search.page.next\")\n",
        "    has_next = \"disabled\" not in next_btn.get_attribute(\"class\").split(\" \")\n",
        "    Page = 1\n",
        "    while has_next: # 다음 페이지가 있으면 loop\n",
        "      \n",
        "    # for i in range(2, 6): # 2, 3, 4, 5\n",
        "        file = open(fileName, 'a', encoding='utf-8')\n",
        "        time.sleep(1)\n",
        "\n",
        "        #info\\.search\\.page\\.no1 ~ .no5\n",
        "        page_links = driver.find_elements(By.CSS_SELECTOR,\"#info\\.search\\.page a\")\n",
        "        pages = [link for link in page_links if \"HIDDEN\" not in link.get_attribute(\"class\").split(\" \")]\n",
        "        # print(len(pages), \"개의 페이지 있음\")\n",
        "        # pages를 하나씩 클릭하면서\n",
        "        for i in range(1, 6):\n",
        "            xPath = '//*[@id=\"info.search.page.no' + str(i) + '\"]'\n",
        "            try:\n",
        "                page = driver.find_element(By.XPATH,xPath)\n",
        "                page.send_keys(Keys.ENTER)\n",
        "            except ElementNotInteractableException:\n",
        "                print('End of Page')\n",
        "                break;\n",
        "            sleep(1)\n",
        "            place_lists = driver.find_elements(By.CSS_SELECTOR,'#info\\.search\\.place\\.list > li')\n",
        "            for p in place_lists: \n",
        "                store_html = p.get_attribute('innerHTML')\n",
        "                store_info = BeautifulSoup(store_html, \"html.parser\")\n",
        "                # BS -> 분석\n",
        "                #\n",
        "                place_name = store_info.select('.head_item > .tit_name > .link_name')\n",
        "                # print(place_name)\n",
        "\n",
        "                if len(place_name) == 0:\n",
        "                    continue # 광고\n",
        "                place_name = store_info.select('.head_item > .tit_name > .link_name')[0].text\n",
        "                place_type = store_info.select('.head_item > .subcategory')[0].text\n",
        "                place_address = store_info.select('.info_item > .addr > p')[0].text\n",
        "                place_address2 = place_address.replace(',', '')\n",
        "                place_hour = store_info.select('.info_item > .openhour > p > a')[0].text\n",
        "                place_hour2 = place_hour.replace(',', '')\n",
        "                place_tel = store_info.select('.info_item > .contact > span')[0].text\n",
        "                place_star = store_info.select('div.rating.clickArea > span.score > em')[0].text\n",
        "                url = store_info.select(\"div.info_item > div.contact.clickArea > a.moreview\")\n",
        "                for j in url:\n",
        "                  link = j[\"href\"]\n",
        "                  print(link)\n",
        "                  file.write(link+\"|\")\n",
        "                \n",
        "  \n",
        "                # 사진url 수집\n",
        "                detail = p.find_element(By.CSS_SELECTOR,'div.info_item > div.contact.clickArea > a.moreview')\n",
        "                \n",
        "                detail.send_keys(Keys.ENTER)\n",
        "\n",
        "                #상세탭으로 전환\n",
        "                driver.switch_to.window(driver.window_handles[-1])\n",
        "                time.sleep(1)\n",
        "                place_photo = \"\"\n",
        "                try:\n",
        "                    photo = driver.find_element(By.CSS_SELECTOR,'span.bg_present')\n",
        "                    photo_url = photo.get_attribute('style')\n",
        "                    m = re.search('\"(.+?)\"', photo_url)\n",
        "                    if m:\n",
        "                        place_photo = m.group(1)\n",
        "                    else:\n",
        "                        place_photo = \"\"\n",
        "                except:\n",
        "                    place_photo = \"\"\n",
        "\n",
        "                driver.close()\n",
        "                driver.switch_to.window(driver.window_handles[0])\n",
        "                time.sleep(1)\n",
        "                print(place_name, place_photo,place_star)\n",
        "                k+=1\n",
        "                file.write(\"MA\"+ \"|\"+str(k)+\"|\"+place_name + \"|\" + place_type +\"|\" + place_address2 + \"|\" + place_hour2 + \"|\" + place_tel + \"|\" + place_photo + \"|\"+ place_star +\"\\n\")\n",
        "            print(i, ' of', ' [ ' , Page, ' ] ')\n",
        "        next_btn = driver.find_element(By.ID,\"info.search.page.next\")\n",
        "        has_next = \"disabled\" not in next_btn.get_attribute(\"class\").split(\" \")\n",
        "        if not has_next:\n",
        "            print('Arrow is Disabled')\n",
        "            driver.close()\n",
        "            file.close()\n",
        "            break # 다음 페이지 없으니까 종료\n",
        "        else: # 다음 페이지 있으면\n",
        "            Page += 1\n",
        "            driver.execute_script(\"arguments[0].click();\",next_btn)\n",
        "    print(\"End of Crawl\")\n"
      ],
      "metadata": {
        "id": "Pajj-aL_rVkk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}